{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f6bd269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, Activation, Flatten, Dense, Input, Lambda, Permute, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from dataprep.event import Event\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac484269",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 23:27:11.381052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 23:27:11.412152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 23:27:11.412308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 23:27:11.412663: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-03 23:27:11.413615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 23:27:11.413804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 23:27:11.413919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 23:27:11.799431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 23:27:11.799592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 23:27:11.799714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-03 23:27:11.799827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4128 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import pickle, gzip\n",
    "\n",
    "class MyUnpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if name == \"Event\" and module == 'event':\n",
    "            return Event\n",
    "        else:\n",
    "            return pickle.Unpickler.find_class(self, module, name)\n",
    "\n",
    "# with open('data/ES_clean_0.pkl', 'rb') as f:\n",
    "def gen_event(quiet=False):\n",
    "    for file_id in range(50):\n",
    "        if not quiet:\n",
    "            print(f\"Starting File {file_id}\")\n",
    "        dataset = MyUnpickler(open(f'data/ES_clean_{file_id}.pkl', 'rb')).load()\n",
    "        for event in dataset:\n",
    "            yield event\n",
    "\n",
    "nevents = sum(1 for _ in gen_event(quiet=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2595cf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 12, 2560, 4492)]  0         \n",
      "                                                                 \n",
      " swap_axis (Permute)         (None, 2560, 4492, 12)    0         \n",
      "                                                                 \n",
      " conv_1 (Conv1D)             (None, 2560, 4365, 16)    24592     \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 640, 272, 16)      16400     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2785280)           0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 2785281   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,826,273\n",
      "Trainable params: 2,826,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "map_shape = (12, 2560, 4492)\n",
    "x = Input(shape=map_shape)\n",
    "# y = Lambda(sparse.to_dense)(x)\n",
    "# y = Reshape(map_shape)(y)\n",
    "y = Permute((2, 3, 1), input_shape=map_shape, name='swap_axis')(x)\n",
    "\n",
    "y = Conv1D(filters=16, kernel_size=128, activation='relu', name=\"conv_1\")(y)\n",
    "y = Conv2D(filters=16, kernel_size=(4, 16), strides=(4, 16), activation='relu', name=\"conv_2\")(y)\n",
    "y = Flatten(name='flatten')(y)\n",
    "y = Dense(1, activation='relu', name='output')(y)\n",
    "model = Model(x, y, name='model')\n",
    "model.compile(loss='mean_absolute_error', optimizer=Adam(learning_rate))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a9a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/1000 [00:00<?, ?it/s]2022-05-03 23:27:20.978145: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8303\n",
      "100%|████████████████████████████████████████████████████████████████████| 1000/1000 [15:05<00:00,  1.10it/s, loss=3.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.95494685435295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1000/1000 [15:07<00:00,  1.10it/s, loss=3.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.955596037626266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████▋                                                            | 126/1000 [01:55<13:23,  1.09it/s, loss=48.2]\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "loss_history = []\n",
    "for idx in range(epochs):\n",
    "    all_loss_in_epoch = []\n",
    "    pbar = tqdm(gen_event(quiet=True), total=nevents)\n",
    "    for event in pbar:\n",
    "        X_train = event.digit_map\n",
    "        Y_train = event.e_energy\n",
    "        X_train = tf.cast(X_train, tf.int16)\n",
    "        X_dense = tf.expand_dims(sparse.to_dense(X_train), axis=0)\n",
    "        y = tf.constant([Y_train])\n",
    "        loss = model.train_on_batch([X_dense], [y])\n",
    "        all_loss_in_epoch.append(loss)\n",
    "        pbar.set_postfix({'loss': loss})\n",
    "    print(np.mean(all_loss_in_epoch))\n",
    "    loss_history.append(np.mean(all_loss_in_epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18deae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(loss_history)\n",
    "# plt.ylim(top=1e4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
